{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d1abcd-65ed-45e3-82c6-b5d7de5f9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# \n",
    "from causalnex.structure import StructureModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbb5202-76eb-4610-87ec-9851ac4ee72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StructureModel with 3 nodes and 2 edges'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = StructureModel()\n",
    "sm.add_edges_from([\n",
    "    ('health', 'absences'),\n",
    "    ('health', 'G1')\n",
    "])\n",
    "sm = StructureModel()\n",
    "sm.add_edges_from([\n",
    "    ('health', 'absences'),\n",
    "    ('health', 'G1')\n",
    "])\n",
    "str(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b98b387-64d4-4751-9c00-0ed7313c50c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"Nodes\": [\\n        \"health\",\\n        \"absences\",\\n        \"G1\"\\n    ],\\n    \"Edges\": [\\n        {\\n            \"color\": \"#ffffffaa\",\\n            \"arrows\": {\\n                \"to\": {\\n                    \"enabled\": true,\\n                    \"scaleFactor\": 0.5\\n                }\\n            },\\n            \"endPointOffset\": {\\n                \"from\": 1,\\n                \"to\": -1\\n            },\\n            \"width\": 2,\\n            \"length\": 15,\\n            \"from\": \"health\",\\n            \"to\": \"absences\"\\n        },\\n        {\\n            \"color\": \"#ffffffaa\",\\n            \"arrows\": {\\n                \"to\": {\\n                    \"enabled\": true,\\n                    \"scaleFactor\": 0.5\\n                }\\n            },\\n            \"endPointOffset\": {\\n                \"from\": 1,\\n                \"to\": -1\\n            },\\n            \"width\": 2,\\n            \"length\": 15,\\n            \"from\": \"health\",\\n            \"to\": \"G1\"\\n        }\\n    ],\\n    \"Height\": \"600px\",\\n    \"Width\": \"100%\",\\n    \"Heading\": \"\"\\n}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "str(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0df18ae-9a02-4705-9939-98ada3b5cb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_simple_plot.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"01_simple_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x252c02fe980>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz.show(\"01_simple_plot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8ad79d-f34e-4ee2-83bd-2e6cd5220ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     address famsize Pstatus  Medu  Fedu  traveltime  studytime  failures  \\\n",
       "0         U     GT3       A     4     4           2          2         0   \n",
       "1         U     GT3       T     1     1           1          2         0   \n",
       "2         U     LE3       T     1     1           1          2         0   \n",
       "3         U     GT3       T     4     2           1          3         0   \n",
       "4         U     GT3       T     3     3           1          2         0   \n",
       "..      ...     ...     ...   ...   ...         ...        ...       ...   \n",
       "644       R     GT3       T     2     3           1          3         1   \n",
       "645       U     LE3       T     3     1           1          2         0   \n",
       "646       U     GT3       T     1     1           2          2         0   \n",
       "647       U     LE3       T     3     1           2          1         0   \n",
       "648       R     LE3       T     3     2           3          1         0   \n",
       "\n",
       "    schoolsup famsup  ... famrel freetime goout Dalc Walc health  absences  \\\n",
       "0         yes     no  ...      4        3     4    1    1      3         4   \n",
       "1          no    yes  ...      5        3     3    1    1      3         2   \n",
       "2         yes     no  ...      4        3     2    2    3      3         6   \n",
       "3          no    yes  ...      3        2     2    1    1      5         0   \n",
       "4          no    yes  ...      4        3     2    1    2      5         0   \n",
       "..        ...    ...  ...    ...      ...   ...  ...  ...    ...       ...   \n",
       "644        no     no  ...      5        4     2    1    2      5         4   \n",
       "645        no    yes  ...      4        3     4    1    1      1         4   \n",
       "646        no     no  ...      1        1     1    1    1      5         6   \n",
       "647        no     no  ...      2        4     5    3    4      2         6   \n",
       "648        no     no  ...      4        4     1    3    4      5         4   \n",
       "\n",
       "     G1  G2  G3  \n",
       "0     0  11  11  \n",
       "1     9  11  11  \n",
       "2    12  13  12  \n",
       "3    14  14  14  \n",
       "4    11  13  13  \n",
       "..   ..  ..  ..  \n",
       "644  10  11  10  \n",
       "645  15  15  16  \n",
       "646  11  12   9  \n",
       "647  10  10  10  \n",
       "648  10  11  11  \n",
       "\n",
       "[649 rows x 26 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('student-por.csv', delimiter=';')\n",
    "drop_col = ['school', 'sex', 'age', 'Mjob', 'Fjob', 'reason', 'guardian']\n",
    "data = data.drop(columns=drop_col)\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79175747-335f-44a9-b1f2-995f3d99036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      address  famsize  Pstatus  Medu  Fedu  traveltime  studytime  failures  \\\n",
       "0          1        0        0     4     4           2          2         0   \n",
       "1          1        0        1     1     1           1          2         0   \n",
       "2          1        1        1     1     1           1          2         0   \n",
       "3          1        0        1     4     2           1          3         0   \n",
       "4          1        0        1     3     3           1          2         0   \n",
       "..       ...      ...      ...   ...   ...         ...        ...       ...   \n",
       "644        0        0        1     2     3           1          3         1   \n",
       "645        1        1        1     3     1           1          2         0   \n",
       "646        1        0        1     1     1           2          2         0   \n",
       "647        1        1        1     3     1           2          1         0   \n",
       "648        0        1        1     3     2           3          1         0   \n",
       "\n",
       "     schoolsup  famsup  ...  famrel  freetime  goout  Dalc  Walc  health  \\\n",
       "0            1       0  ...       4         3      4     1     1       3   \n",
       "1            0       1  ...       5         3      3     1     1       3   \n",
       "2            1       0  ...       4         3      2     2     3       3   \n",
       "3            0       1  ...       3         2      2     1     1       5   \n",
       "4            0       1  ...       4         3      2     1     2       5   \n",
       "..         ...     ...  ...     ...       ...    ...   ...   ...     ...   \n",
       "644          0       0  ...       5         4      2     1     2       5   \n",
       "645          0       1  ...       4         3      4     1     1       1   \n",
       "646          0       0  ...       1         1      1     1     1       5   \n",
       "647          0       0  ...       2         4      5     3     4       2   \n",
       "648          0       0  ...       4         4      1     3     4       5   \n",
       "\n",
       "     absences  G1  G2  G3  \n",
       "0           4   0  11  11  \n",
       "1           2   9  11  11  \n",
       "2           6  12  13  12  \n",
       "3           0  14  14  14  \n",
       "4           0  11  13  13  \n",
       "..        ...  ..  ..  ..  \n",
       "644         4  10  11  10  \n",
       "645         4  15  15  16  \n",
       "646         6  11  12   9  \n",
       "647         6  10  10  10  \n",
       "648         4  10  11  11  \n",
       "\n",
       "[649 rows x 26 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "struct_data = data.copy()\n",
    "non_numeric_columns = list(struct_data.select_dtypes(exclude=[np.number]).columns)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    struct_data[col] = le.fit_transform(struct_data[col])\n",
    "\n",
    "struct_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8b3558d-c5f9-4fe9-9d88-d36f6a9421d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_thresholded.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"01_thresholded.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x280f0447ee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "from pyvis.network import Network\n",
    "\n",
    "sm = from_pandas(struct_data)  # tabu_edges to avoid erroneous relationships manually\n",
    "sm.remove_edges_below_threshold(0.8) # From 650 to 14 edges\n",
    "\n",
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"01_thresholded.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f880bce-b620-412d-930c-7255c67cc52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_edge_added.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"01_edge_added.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x280f04437f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = from_pandas(struct_data, tabu_edges=[(\"higher\", \"Medu\")], w_threshold=0.8)\n",
    "\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"01_edge_added.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef653a-6b17-4f03-a7a1-09789710f725",
   "metadata": {},
   "source": [
    "### Modifying the Structure\n",
    "To correct erroneous relationships, we can incorporate domain knowledge into the model after structure learning. We can modify the structure model through adding and deleting the edges. For example, we can add and remove edges as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6838656b-a570-416d-b6cd-08fcbad024cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.add_edge(\"failures\", \"G1\")\n",
    "sm.remove_edge(\"Pstatus\", \"G1\")\n",
    "sm.remove_edge(\"address\", \"G1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf49e53-3716-4410-b0f0-b75c7ca19e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_modified_structure.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"01_modified_structure.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x280f06c1e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"01_modified_structure.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f6af79a-70ea-43c5-9304-9cf22c0a0cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_largest_subgraph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"01_largest_subgraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x280a3bb67d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = sm.get_largest_subgraph()\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"01_largest_subgraph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f12b8f6-ec3b-408f-bfe5-4e8d33d8f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx.drawing.nx_pydot.write_dot(sm, 'graph.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95098202-f850-4298-8031-d1dc0ac7e871",
   "metadata": {},
   "source": [
    "### Fitting the Conditional Distribution of the Bayesian Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f781a11d-d9e0-495c-bf2c-381b018bafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.network import BayesianNetwork\n",
    "\n",
    "bn = BayesianNetwork(sm)\n",
    "\n",
    "discretised_data = data.copy()\n",
    "\n",
    "data_vals = {col: data[col].unique() for col in data.columns}\n",
    "\n",
    "failures_map = {v: 'no-failure' if v == [0]\n",
    "                else 'have-failure' for v in data_vals['failures']}\n",
    "studytime_map = {v: 'short-studytime' if v in [1,2]\n",
    "                 else 'long-studytime' for v in data_vals['studytime']}\n",
    "\n",
    "discretised_data[\"failures\"] = discretised_data[\"failures\"].map(failures_map)\n",
    "discretised_data[\"studytime\"] = discretised_data[\"studytime\"].map(studytime_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71532a94-604c-45da-aedd-9180bce544f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     address famsize Pstatus  Medu  Fedu  traveltime        studytime  \\\n",
       "0         U     GT3       A     4     4           2  short-studytime   \n",
       "1         U     GT3       T     1     1           1  short-studytime   \n",
       "2         U     LE3       T     1     1           1  short-studytime   \n",
       "3         U     GT3       T     4     2           1   long-studytime   \n",
       "4         U     GT3       T     3     3           1  short-studytime   \n",
       "..      ...     ...     ...   ...   ...         ...              ...   \n",
       "644       R     GT3       T     2     3           1   long-studytime   \n",
       "645       U     LE3       T     3     1           1  short-studytime   \n",
       "646       U     GT3       T     1     1           2  short-studytime   \n",
       "647       U     LE3       T     3     1           2  short-studytime   \n",
       "648       R     LE3       T     3     2           3  short-studytime   \n",
       "\n",
       "         failures schoolsup famsup  ... famrel freetime goout Dalc Walc  \\\n",
       "0      no-failure       yes     no  ...      4        3     4    1    1   \n",
       "1      no-failure        no    yes  ...      5        3     3    1    1   \n",
       "2      no-failure       yes     no  ...      4        3     2    2    3   \n",
       "3      no-failure        no    yes  ...      3        2     2    1    1   \n",
       "4      no-failure        no    yes  ...      4        3     2    1    2   \n",
       "..            ...       ...    ...  ...    ...      ...   ...  ...  ...   \n",
       "644  have-failure        no     no  ...      5        4     2    1    2   \n",
       "645    no-failure        no    yes  ...      4        3     4    1    1   \n",
       "646    no-failure        no     no  ...      1        1     1    1    1   \n",
       "647    no-failure        no     no  ...      2        4     5    3    4   \n",
       "648    no-failure        no     no  ...      4        4     1    3    4   \n",
       "\n",
       "    health  absences  G1  G2  G3  \n",
       "0        3         4   0  11  11  \n",
       "1        3         2   9  11  11  \n",
       "2        3         6  12  13  12  \n",
       "3        5         0  14  14  14  \n",
       "4        5         0  11  13  13  \n",
       "..     ...       ...  ..  ..  ..  \n",
       "644      5         4  10  11  10  \n",
       "645      1         4  15  15  16  \n",
       "646      5         6  11  12   9  \n",
       "647      2         6  10  10  10  \n",
       "648      5         4  10  11  11  \n",
       "\n",
       "[649 rows x 26 columns]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretised_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bbeb207-48c7-4774-b7f9-578701dc6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.discretiser import Discretiser\n",
    "\n",
    "discretised_data[\"absences\"] = Discretiser(method=\"fixed\",\n",
    "                          numeric_split_points=[1, 10]).transform(discretised_data[\"absences\"].values)\n",
    "discretised_data[\"G1\"] = Discretiser(method=\"fixed\",\n",
    "                          numeric_split_points=[10]).transform(discretised_data[\"G1\"].values)\n",
    "discretised_data[\"G2\"] = Discretiser(method=\"fixed\",\n",
    "                          numeric_split_points=[10]).transform(discretised_data[\"G2\"].values)\n",
    "discretised_data[\"G3\"] = Discretiser(method=\"fixed\",\n",
    "                          numeric_split_points=[10]).transform(discretised_data[\"G3\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7347ed48-3ec9-4a70-b536-531d79e7b934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     address famsize Pstatus  Medu  Fedu  traveltime        studytime  \\\n",
       "0         U     GT3       A     4     4           2  short-studytime   \n",
       "1         U     GT3       T     1     1           1  short-studytime   \n",
       "2         U     LE3       T     1     1           1  short-studytime   \n",
       "3         U     GT3       T     4     2           1   long-studytime   \n",
       "4         U     GT3       T     3     3           1  short-studytime   \n",
       "..      ...     ...     ...   ...   ...         ...              ...   \n",
       "644       R     GT3       T     2     3           1   long-studytime   \n",
       "645       U     LE3       T     3     1           1  short-studytime   \n",
       "646       U     GT3       T     1     1           2  short-studytime   \n",
       "647       U     LE3       T     3     1           2  short-studytime   \n",
       "648       R     LE3       T     3     2           3  short-studytime   \n",
       "\n",
       "         failures schoolsup famsup  ... famrel freetime goout Dalc Walc  \\\n",
       "0      no-failure       yes     no  ...      4        3     4    1    1   \n",
       "1      no-failure        no    yes  ...      5        3     3    1    1   \n",
       "2      no-failure       yes     no  ...      4        3     2    2    3   \n",
       "3      no-failure        no    yes  ...      3        2     2    1    1   \n",
       "4      no-failure        no    yes  ...      4        3     2    1    2   \n",
       "..            ...       ...    ...  ...    ...      ...   ...  ...  ...   \n",
       "644  have-failure        no     no  ...      5        4     2    1    2   \n",
       "645    no-failure        no    yes  ...      4        3     4    1    1   \n",
       "646    no-failure        no     no  ...      1        1     1    1    1   \n",
       "647    no-failure        no     no  ...      2        4     5    3    4   \n",
       "648    no-failure        no     no  ...      4        4     1    3    4   \n",
       "\n",
       "    health     absences    G1    G2    G3  \n",
       "0        3  Low-absence  Fail  Pass  Pass  \n",
       "1        3  Low-absence  Fail  Pass  Pass  \n",
       "2        3  Low-absence  Pass  Pass  Pass  \n",
       "3        5   No-absence  Pass  Pass  Pass  \n",
       "4        5   No-absence  Pass  Pass  Pass  \n",
       "..     ...          ...   ...   ...   ...  \n",
       "644      5  Low-absence  Pass  Pass  Pass  \n",
       "645      1  Low-absence  Pass  Pass  Pass  \n",
       "646      5  Low-absence  Pass  Pass  Fail  \n",
       "647      2  Low-absence  Pass  Pass  Pass  \n",
       "648      5  Low-absence  Pass  Pass  Pass  \n",
       "\n",
       "[649 rows x 26 columns]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absences_map = {0: \"No-absence\", 1: \"Low-absence\", 2: \"High-absence\"}\n",
    "\n",
    "G1_map = {0: \"Fail\", 1: \"Pass\"}\n",
    "G2_map = {0: \"Fail\", 1: \"Pass\"}\n",
    "G3_map = {0: \"Fail\", 1: \"Pass\"}\n",
    "\n",
    "discretised_data[\"absences\"] = discretised_data[\"absences\"].map(absences_map)\n",
    "discretised_data[\"G1\"] = discretised_data[\"G1\"].map(G1_map)\n",
    "discretised_data[\"G2\"] = discretised_data[\"G2\"].map(G2_map)\n",
    "discretised_data[\"G3\"] = discretised_data[\"G3\"].map(G3_map)\n",
    "\n",
    "discretised_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "addebaf6-5451-404d-8882-c6f190bd9db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\Users\\DavidBlazquezGarcia\\anaconda3\\envs\\py310\\lib\\site-packages\\causalnex\\network\\network.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <th colspan=\"8\" halign=\"left\">have-failure</th>\n",
       "      <th colspan=\"8\" halign=\"left\">no-failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher</th>\n",
       "      <th colspan=\"4\" halign=\"left\">no</th>\n",
       "      <th colspan=\"4\" halign=\"left\">yes</th>\n",
       "      <th colspan=\"4\" halign=\"left\">no</th>\n",
       "      <th colspan=\"4\" halign=\"left\">yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup</th>\n",
       "      <th colspan=\"2\" halign=\"left\">no</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">no</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">no</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">no</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "      <th>long-studytime</th>\n",
       "      <th>short-studytime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fail</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.15016</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pass</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.84984</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.744186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "failures    have-failure                                                 \\\n",
       "higher                no                                                  \n",
       "schoolsup             no                            yes                   \n",
       "studytime long-studytime short-studytime long-studytime short-studytime   \n",
       "G1                                                                        \n",
       "Fail                0.75        0.806452            0.5            0.75   \n",
       "Pass                0.25        0.193548            0.5            0.25   \n",
       "\n",
       "failures                                                                 \\\n",
       "higher               yes                                                  \n",
       "schoolsup             no                            yes                   \n",
       "studytime long-studytime short-studytime long-studytime short-studytime   \n",
       "G1                                                                        \n",
       "Fail                 0.5        0.612245            0.5            0.75   \n",
       "Pass                 0.5        0.387755            0.5            0.25   \n",
       "\n",
       "failures      no-failure                                                 \\\n",
       "higher                no                                                  \n",
       "schoolsup             no                            yes                   \n",
       "studytime long-studytime short-studytime long-studytime short-studytime   \n",
       "G1                                                                        \n",
       "Fail                 0.5        0.612903            0.5             0.5   \n",
       "Pass                 0.5        0.387097            0.5             0.5   \n",
       "\n",
       "failures                                                                 \n",
       "higher               yes                                                 \n",
       "schoolsup             no                            yes                  \n",
       "studytime long-studytime short-studytime long-studytime short-studytime  \n",
       "G1                                                                       \n",
       "Fail            0.032967         0.15016       0.111111        0.255814  \n",
       "Pass            0.967033         0.84984       0.888889        0.744186  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split 90% train and 10% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(discretised_data, train_size=0.9, test_size=0.1, random_state=7)\n",
    "bn = bn.fit_node_states(discretised_data)\n",
    "bn = bn.fit_cpds(train, method=\"BayesianEstimator\", bayes_prior=\"K2\")\n",
    "bn.cpds[\"G1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "462f5ebf-615b-4517-913e-d778307e92fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address                     U\n",
       "famsize                   GT3\n",
       "Pstatus                     T\n",
       "Medu                        3\n",
       "Fedu                        2\n",
       "traveltime                  1\n",
       "studytime     short-studytime\n",
       "failures         have-failure\n",
       "schoolsup                  no\n",
       "famsup                    yes\n",
       "paid                      yes\n",
       "activities                yes\n",
       "nursery                   yes\n",
       "higher                    yes\n",
       "internet                  yes\n",
       "romantic                   no\n",
       "famrel                      5\n",
       "freetime                    5\n",
       "goout                       5\n",
       "Dalc                        2\n",
       "Walc                        4\n",
       "health                      5\n",
       "absences          Low-absence\n",
       "G2                       Fail\n",
       "G3                       Fail\n",
       "Name: 18, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretised_data.loc[18, discretised_data.columns != 'G1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a36248d-17df-40db-a538-d65f928491c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction is 'Fail'\n"
     ]
    }
   ],
   "source": [
    "predictions = bn.predict(discretised_data, \"G1\")\n",
    "print(f\"The prediction is '{predictions.loc[18, 'G1_prediction']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3545c8b-7932-4afd-99cc-e6af001c9f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth is 'Fail'\n"
     ]
    }
   ],
   "source": [
    "print(f\"The ground truth is '{discretised_data.loc[18, 'G1']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d75668-c305-4a08-9012-56f9f2dfd662",
   "metadata": {},
   "source": [
    "### Model Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82d83111-2967-4031-9104-954216477b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G1_Fail': {'precision': 0.7777777777777778,\n",
       "  'recall': 0.5833333333333334,\n",
       "  'f1-score': 0.6666666666666666,\n",
       "  'support': 12.0},\n",
       " 'G1_Pass': {'precision': 0.9107142857142857,\n",
       "  'recall': 0.9622641509433962,\n",
       "  'f1-score': 0.9357798165137615,\n",
       "  'support': 53.0},\n",
       " 'accuracy': 0.8923076923076924,\n",
       " 'macro avg': {'precision': 0.8442460317460317,\n",
       "  'recall': 0.7727987421383649,\n",
       "  'f1-score': 0.8012232415902141,\n",
       "  'support': 65.0},\n",
       " 'weighted avg': {'precision': 0.8861721611721611,\n",
       "  'recall': 0.8923076923076924,\n",
       "  'f1-score': 0.8860973888496825,\n",
       "  'support': 65.0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from causalnex.evaluation import classification_report\n",
    "\n",
    "classification_report(bn, test, \"G1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a0d7588-16f7-4432-ba7f-d2d7a777de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9181065088757396\n"
     ]
    }
   ],
   "source": [
    "from causalnex.evaluation import roc_auc\n",
    "roc, auc = roc_auc(bn, test, \"G1\")\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
